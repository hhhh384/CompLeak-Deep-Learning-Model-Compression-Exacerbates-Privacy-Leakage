{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38d184c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset\n",
    "from base_model import BaseModel\n",
    "import pickle\n",
    "import numpy as np\n",
    "import warnings\n",
    "import random\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import ast\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from data_utils import get_dataset\n",
    "from collections import Counter\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03ae3125",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "device = f\"cuda:{0}\"\n",
    "cpu_device = torch.device(\"cpu:0\")\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf7185a3-afdf-41f7-811e-9b2568819060",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 3\n",
    "dataset_name = \"cifar10\"\n",
    "model_name = \"resnet18\"\n",
    "num_cls = 10\n",
    "shadow_num = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a72b1e-f7b0-4fce-bf05-c2e80a607a0a",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "313fe371-5f0d-4991-815c-220378a8ea05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build Dataset cifar10\n",
      "Build Dataset cifar10\n"
     ]
    }
   ],
   "source": [
    "trainset = get_dataset(dataset_name, train=True)\n",
    "testset = get_dataset(dataset_name, train=False)    \n",
    "data_path = f\"data/{dataset_name}_data_index_inference.pkl\"\n",
    "    \n",
    "with open(data_path, 'rb') as f:\n",
    "    inference_victim_train_list, inference_victim_test_list, inference_attack_split_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa73031e-0187-4201-883d-b85b02781f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder_original = f\"results/{dataset_name}_{model_name}\"\n",
    "save_folder_compress = f\"results_pruning/{dataset_name}_{model_name}\"\n",
    "save_folder_compress_q = f\"results_quantization/{dataset_name}_{model_name}\"\n",
    "#save_folder_compress_c = f\"results_clustering/{dataset_name}_{model_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f64a4760-1e7b-4a75-a2c5-0d7d19169936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Victim Train Size: 10000, Victim Test Size: 10000\n"
     ]
    }
   ],
   "source": [
    "victim_train_dataset = Subset(trainset, inference_victim_train_list)\n",
    "victim_test_dataset = Subset(testset, inference_victim_test_list)\n",
    "print(f\"Victim Train Size: {len(inference_victim_train_list)}, \"\n",
    "        f\"Victim Test Size: {len(inference_victim_test_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "617111a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "victim_train_loader = DataLoader(victim_train_dataset, batch_size=128, shuffle=False)\n",
    "victim_test_loader = DataLoader(victim_test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026a22a2-2ca6-42f8-87d4-dc8be018f44c",
   "metadata": {},
   "source": [
    "# Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f20c1af-2773-4565-9b83-115875587210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load victim model\n",
    "victim_model_save_folder = save_folder_original + \"/victim_model\"\n",
    "victim_model_path = f\"{victim_model_save_folder}/best.pth\"\n",
    "victim_model = BaseModel(dataset_name, model_name, num_cls=num_cls, input_dim=input_dim, device=device)\n",
    "victim_model.load(victim_model_path)\n",
    "\n",
    "victim_original_in_loss, victim_in_target, victim_original_in_predicts = victim_model.loss_target_predict(victim_train_loader)\n",
    "victim_original_out_loss, victim_out_target, victim_original_out_predicts = victim_model.loss_target_predict(victim_test_loader)\n",
    "sort_victim_original_in = torch.argsort(victim_original_in_predicts, dim=1, descending=False)\n",
    "sort_victim_original_out = torch.argsort(victim_original_out_predicts, dim=1, descending=False)\n",
    "victim_original_in_predicts = torch.gather(victim_original_in_predicts, 1, sort_victim_original_in)\n",
    "victim_original_out_predicts = torch.gather(victim_original_out_predicts, 1, sort_victim_original_out)\n",
    "victim_original_in_loss = victim_original_in_loss.unsqueeze(1)\n",
    "victim_original_out_loss = victim_original_out_loss.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fa61742-0e38-4ee4-9dd6-0327d98c7b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Compress Model from results_pruning/cifar10_resnet18_0.6/victim_model\n",
      "Load Compress Model from results_pruning/cifar10_resnet18_0.7/victim_model\n",
      "Load Compress Model from results_pruning/cifar10_resnet18_0.8/victim_model\n",
      "Load Compress Model from results_pruning/cifar10_resnet18_0.9/victim_model\n"
     ]
    }
   ],
   "source": [
    "victim_compress_model_list = []\n",
    "for i in [0.6, 0.7, 0.8, 0.9]: # different prune levels\n",
    "    compress_victim_model_save_folder = f\"{save_folder_compress}_{i}/victim_model\"\n",
    "    print(f\"Load Compress Model from {compress_victim_model_save_folder}\")\n",
    "    victim_compress_model = BaseModel(dataset_name, model_name, num_cls=num_cls, input_dim=input_dim, save_folder=compress_victim_model_save_folder, device=device)\n",
    "    victim_compress_model.model.load_state_dict(torch.load(f\"{compress_victim_model_save_folder}/best.pth\"))\n",
    "    victim_compress_model_list.append(victim_compress_model)\n",
    "\n",
    "victim_compress_model = BaseModel(dataset_name, model_name, num_cls=num_cls, input_dim=input_dim, device=torch.device(\"cpu:0\"))\n",
    "victim_compress_model.load_torchscript_model(f\"results_quantization/{dataset_name}_{model_name}_int8/victim_model/best.pth\")\n",
    "victim_compress_model_list.append(victim_compress_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd0f6e00-3ecc-4218-b35d-a51b5288a4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(victim_compress_model_list))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cc9253c3-ff2c-4e61-993c-f3b9aec3a361",
   "metadata": {},
   "source": [
    "For the quantized model, only the INT8 version is available. To load the model, use \n",
    "victim_compress_model.load_torchscript_model(f\"{compress_victim_model_save_folder}/best.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34bb08c7-1038-487c-91ee-1261c4617146",
   "metadata": {},
   "outputs": [],
   "source": [
    "victim_compress_in_predicts_list = []\n",
    "victim_compress_out_predicts_list = []\n",
    "victim_compress_in_loss_list = []\n",
    "victim_compress_out_loss_list = []\n",
    "victim_compress_in_state_list = []\n",
    "victim_compress_out_state_list = []\n",
    "for victim_compress_model in victim_compress_model_list:\n",
    "    victim_compress_in_loss,victim_in_target, victim_compress_in_predicts = victim_compress_model.loss_target_predict(victim_train_loader)\n",
    "    victim_compress_out_loss, victim_out_target, victim_compress_out_predicts = victim_compress_model.loss_target_predict(victim_test_loader)\n",
    "    \n",
    "    victim_compress_in_predicts =  victim_compress_in_predicts.gather(1, sort_victim_original_in)\n",
    "    victim_compress_in_predicts = victim_original_in_predicts - victim_compress_in_predicts\n",
    "    victim_compress_out_predicts =  victim_compress_out_predicts.gather(1, sort_victim_original_out)\n",
    "    victim_compress_out_predicts = victim_original_out_predicts - victim_compress_out_predicts\n",
    "    \n",
    "    victim_compress_in_predicts_list.append(victim_compress_in_predicts)\n",
    "    victim_compress_out_predicts_list.append(victim_compress_out_predicts)\n",
    "    victim_compress_in_loss_list.append(victim_compress_in_loss)\n",
    "    victim_compress_out_loss_list.append(victim_compress_out_loss)\n",
    "\n",
    "victim_compress_in_loss_list = [x.unsqueeze(1) for x in victim_compress_in_loss_list]  \n",
    "victim_compress_out_loss_list = [x.unsqueeze(1) for x in victim_compress_out_loss_list]   \n",
    "victim_compress_in_predicts = torch.cat(victim_compress_in_predicts_list, dim=1)\n",
    "victim_compress_out_predicts = torch.cat(victim_compress_out_predicts_list, dim=1)\n",
    "victim_compress_in_loss = torch.cat(victim_compress_in_loss_list, dim=1)\n",
    "victim_compress_out_loss = torch.cat(victim_compress_out_loss_list, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c592b43-3c4e-4f05-9118-4d4007a25178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7739b02c-2103-4a25-b7e2-fc6d42823037",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37d4dee9-c0e0-48c2-812b-9b7563d4fb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load compress Shadow Model From results_pruning/cifar10_resnet18_0.6/shadow_model_0\n",
      "Load compress Shadow Model From results_pruning/cifar10_resnet18_0.7/shadow_model_0\n",
      "Load compress Shadow Model From results_pruning/cifar10_resnet18_0.8/shadow_model_0\n",
      "Load compress Shadow Model From results_pruning/cifar10_resnet18_0.9/shadow_model_0\n"
     ]
    }
   ],
   "source": [
    "shadow_model_list, shadow_train_loader_list, shadow_test_loader_list, shadow_prune_model_group_list = [], [], [], []\n",
    "\n",
    "for shadow_ind in range(shadow_num):\n",
    "    attack_train_list, attack_test_list = inference_attack_split_list[shadow_ind]\n",
    "    shadow_train_dataset = Subset(trainset, attack_train_list)\n",
    "    shadow_test_dataset = Subset(testset, attack_test_list)\n",
    "    shadow_train_loader = DataLoader(shadow_train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    shadow_test_loader = DataLoader(shadow_test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    shadow_model_path = f\"{save_folder_original}/shadow_model_{shadow_ind}/best.pth\"\n",
    "    shadow_model = BaseModel(dataset_name,model_name, num_cls=num_cls, input_dim=input_dim, device=device)\n",
    "    shadow_model.load(shadow_model_path)\n",
    "    shadow_model_list.append(shadow_model)\n",
    "    shadow_train_loader_list.append(shadow_train_loader)\n",
    "    shadow_test_loader_list.append(shadow_test_loader)\n",
    "    shadow_prune_model_list = []\n",
    "    for i in [0.6, 0.7, 0.8, 0.9]:\n",
    "        compress_shadow_model_save_folder = f\"{save_folder_compress}_{i}/shadow_model_{shadow_ind}\"\n",
    "        print(f\"Load compress Shadow Model From {compress_shadow_model_save_folder}\")\n",
    "        shadow_compress_model = BaseModel(dataset_name,model_name, num_cls=num_cls, input_dim=input_dim,save_folder=compress_shadow_model_save_folder, device=device)\n",
    "        shadow_compress_model.model.load_state_dict(torch.load(f\"{compress_shadow_model_save_folder}/best.pth\"))\n",
    "        shadow_prune_model_list.append(shadow_compress_model)\n",
    "    shadow_compress_model = BaseModel(dataset_name, model_name, num_cls=num_cls, input_dim=input_dim, device=torch.device(\"cpu:0\"))\n",
    "    shadow_compress_model.load_torchscript_model(f\"results_quantization/{dataset_name}_{model_name}_int8/shadow_model_{shadow_ind}/best.pth\")\n",
    "    shadow_prune_model_list.append(shadow_compress_model)\n",
    "    shadow_prune_model_group_list.append(shadow_prune_model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db8f7a5f-f485-4a64-8455-ee42a016613d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shadow prune model 0 for shadow 1: <base_model.BaseModel object at 0x7fc3e6936a80>\n",
      "Shadow prune model 1 for shadow 1: <base_model.BaseModel object at 0x7fc29b8910a0>\n",
      "Shadow prune model 2 for shadow 1: <base_model.BaseModel object at 0x7fc2aea91640>\n",
      "Shadow prune model 3 for shadow 1: <base_model.BaseModel object at 0x7fc2d68b65a0>\n",
      "Shadow prune model 4 for shadow 1: <base_model.BaseModel object at 0x7fc2aebc5880>\n"
     ]
    }
   ],
   "source": [
    "attack_original_in_predicts_list, attack_original_out_predicts_list = [], []\n",
    "attack_compress_in_predicts_list, attack_compress_out_predicts_list = [], []\n",
    "attack_original_in_loss_list, attack_original_out_loss_list = [], []\n",
    "attack_compress_in_loss_list, attack_compress_out_loss_list = [], []\n",
    "attack_in_targets_list = []\n",
    "attack_out_targets_list= []\n",
    "\n",
    "n = 0\n",
    "\n",
    "for shadow_model, shadow_train_loader, shadow_test_loader in zip(shadow_model_list, shadow_train_loader_list, shadow_test_loader_list):\n",
    "\n",
    "    attack_original_in_loss,attack_in_target, attack_original_in_predicts = shadow_model.loss_target_predict(shadow_train_loader)\n",
    "    attack_original_out_loss, attack_out_target, attack_original_out_predicts = shadow_model.loss_target_predict(shadow_test_loader)\n",
    "\n",
    "    sort_attack_original_in = torch.argsort(attack_original_in_predicts, dim=1, descending=False)\n",
    "    sort_attack_original_out = torch.argsort(attack_original_out_predicts, dim=1, descending=False)\n",
    "    attack_original_in_predicts = torch.gather(attack_original_in_predicts, 1, sort_attack_original_in)\n",
    "    attack_original_out_predicts = torch.gather(attack_original_out_predicts, 1, sort_attack_original_out)\n",
    "    \n",
    "    attack_original_in_loss = attack_original_in_loss.unsqueeze(1)\n",
    "    attack_original_out_loss = attack_original_out_loss.unsqueeze(1)\n",
    "    \n",
    "    attack_original_in_loss_list.append(attack_original_in_loss)\n",
    "    attack_original_out_loss_list.append(attack_original_out_loss)\n",
    "    \n",
    "    attack_original_in_predicts_list.append(attack_original_in_predicts)\n",
    "    attack_original_out_predicts_list.append(attack_original_out_predicts) \n",
    "    attack_in_targets_list.append(attack_in_target)\n",
    "    attack_out_targets_list.append(attack_out_target)  \n",
    "\n",
    "    each_attack_compress_in_predicts_list = []\n",
    "    each_attack_compress_out_predicts_list = []\n",
    "    each_attack_compress_in_loss_list = []\n",
    "    each_attack_compress_out_loss_list = []\n",
    "\n",
    "    shadow_prune_models_for_n = shadow_prune_model_group_list[n]\n",
    "    n = n+1\n",
    "    for i, shadow_prune_model in enumerate(shadow_prune_models_for_n):\n",
    "        print(f\"Shadow prune model {i} for shadow {n}: {shadow_prune_model}\")\n",
    "        attack_compress_out_loss, attack_out_targets, attack_compress_out_predicts = shadow_compress_model.loss_target_predict(shadow_test_loader)\n",
    "        attack_compress_in_loss, attack_in_targets, attack_compress_in_predicts = shadow_compress_model.loss_target_predict(shadow_train_loader)\n",
    "\n",
    "        attack_compress_in_predicts = attack_compress_in_predicts.gather(1, sort_attack_original_in)\n",
    "        attack_compress_out_predicts =  attack_compress_out_predicts.gather(1, sort_attack_original_out)\n",
    "        \n",
    "        attack_compress_in_predicts = attack_original_in_predicts - attack_compress_in_predicts\n",
    "        attack_compress_out_predicts = attack_original_out_predicts - attack_compress_out_predicts\n",
    "        \n",
    "        each_attack_compress_out_predicts_list.append(attack_compress_out_predicts)\n",
    "        each_attack_compress_in_predicts_list.append(attack_compress_in_predicts)\n",
    "\n",
    "        each_attack_compress_in_loss_list.append(attack_compress_in_loss)\n",
    "        each_attack_compress_out_loss_list.append(attack_compress_out_loss)\n",
    "\n",
    "        \n",
    "    each_attack_compress_in_loss_list = [x.unsqueeze(1) for x in each_attack_compress_in_loss_list]  # 增加一个维度\n",
    "    each_attack_compress_out_loss_list = [x.unsqueeze(1) for x in each_attack_compress_out_loss_list]  # 增加一个维度\n",
    "\n",
    "    each_attack_compress_in_predicts = torch.cat(each_attack_compress_in_predicts_list, dim=1)\n",
    "    each_attack_compress_out_predicts = torch.cat(each_attack_compress_out_predicts_list, dim=1)\n",
    "    attack_compress_in_predicts_list.append(each_attack_compress_in_predicts)\n",
    "    attack_compress_out_predicts_list.append(each_attack_compress_out_predicts)\n",
    "\n",
    "    each_attack_compress_in_loss = torch.cat(each_attack_compress_in_loss_list, dim=1)\n",
    "    each_attack_compress_out_loss = torch.cat(each_attack_compress_out_loss_list, dim=1)\n",
    "    attack_compress_in_loss_list.append(each_attack_compress_in_loss)\n",
    "    attack_compress_out_loss_list.append(each_attack_compress_out_loss)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "attack_original_in_predicts = torch.cat(attack_original_in_predicts_list, dim=0)\n",
    "attack_original_out_predicts = torch.cat(attack_original_out_predicts_list, dim=0)\n",
    "attack_compress_in_predicts = torch.cat(attack_compress_in_predicts_list, dim=0)\n",
    "attack_compress_out_predicts = torch.cat(attack_compress_out_predicts_list, dim=0)\n",
    "attack_in_targets = torch.cat(attack_in_targets_list, dim=0)\n",
    "attack_out_targets = torch.cat(attack_out_targets_list, dim=0)\n",
    "\n",
    "attack_original_in_loss = torch.cat(attack_original_in_loss_list, dim=0)\n",
    "attack_original_out_loss = torch.cat(attack_original_out_loss_list, dim=0)\n",
    "\n",
    "attack_compress_in_loss = torch.cat(attack_compress_in_loss_list, dim=0)\n",
    "attack_compress_out_loss = torch.cat(attack_compress_out_loss_list, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43f63d8a-0ea1-479e-a03e-78d7031dea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pre = np.concatenate((attack_compress_in_predicts, attack_compress_out_predicts), axis=0)\n",
    "test_pre = np.concatenate((victim_compress_in_predicts, victim_compress_out_predicts), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86de06d9-bbc3-4eef-b1b9-19f11934cee3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d8f1a28-a300-4ac3-b2d0-55cc594c1f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_in_targets = F.one_hot(attack_in_targets, num_classes=num_cls).float() \n",
    "attack_out_targets = F.one_hot(attack_out_targets, num_classes=num_cls).float()\n",
    "train_target = np.concatenate((attack_in_targets.cpu(), attack_out_targets.cpu()), axis=0)\n",
    "\n",
    "victim_in_targets = F.one_hot(victim_in_target, num_classes=num_cls).float()\n",
    "victim_out_targets = F.one_hot(victim_out_target, num_classes=num_cls).float()\n",
    "test_target = np.concatenate((victim_in_targets.cpu(), victim_out_targets.cpu()), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81f6b5fb-a807-41dc-8318-df8445031721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    }
   ],
   "source": [
    "train_loss = np.concatenate((attack_compress_in_loss, attack_compress_out_loss), axis=0)\n",
    "test_loss = np.concatenate((victim_compress_in_loss, victim_compress_out_loss), axis=0)\n",
    "print(len(train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2aff79bd-f000-40e7-9514-a7bd91e747e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20000])\n",
      "torch.Size([20000])\n"
     ]
    }
   ],
   "source": [
    "num = len(attack_in_targets)\n",
    "total_num = num*shadow_num \n",
    "ones = torch.ones(total_num)\n",
    "zeros = torch.zeros(total_num)\n",
    "train_labels = torch.cat((ones, zeros), dim=0)\n",
    "print(train_labels.shape)\n",
    "\n",
    "ones = torch.ones(num)\n",
    "zeros = torch.zeros(num)\n",
    "test_labels = torch.cat((ones, zeros), dim=0)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7372b2ab-53db-48a8-bdf3-0f10956ec344",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_model_name = \"RF\"\n",
    "method_name = \"CompLeakSR2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e075dcea-5f72-4002-b15d-9f5dcbc14a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def load_attack_probs(\n",
    "    save_folder_compress,\n",
    "    compress_ratio,\n",
    "    attack_model_name,\n",
    "    method_name\n",
    "):\n",
    "    \"\"\"\n",
    "    compress_ratio: float, e.g. 0.6 / 0.7 / 0.8 / 0.9\n",
    "    \"\"\"\n",
    "    csv_path = f\"{save_folder_compress}_{compress_ratio}/{attack_model_name}_CompLeakSR.csv\"\n",
    "    results = pd.read_csv(csv_path)\n",
    "\n",
    "    condition = (\n",
    "        (results['method'] == method_name) &\n",
    "        (results['attack_model_name'] == attack_model_name)\n",
    "    )\n",
    "    prob = results[condition]\n",
    "\n",
    "    train_prob = ast.literal_eval(prob['train_prob'].values[0])\n",
    "    test_prob  = ast.literal_eval(prob['test_prob'].values[0])\n",
    "\n",
    "    train_prob = np.array(train_prob).reshape(-1, 2)\n",
    "    test_prob  = np.array(test_prob).reshape(-1, 2)\n",
    "\n",
    "    return train_prob, test_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ced82f78-3aaf-4f76-b305-fee1210b408b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_concat_dataset(\n",
    "    save_folder_compress,\n",
    "    ratios,\n",
    "    attack_model_name,\n",
    "    method_name\n",
    "):\n",
    "    train_list = []\n",
    "    test_list = []\n",
    "\n",
    "    for r in ratios:\n",
    "        if r == 'int8':\n",
    "            save_folder_compress = save_folder_compress_q\n",
    "        train_prob, test_prob = load_attack_probs(\n",
    "            save_folder_compress,\n",
    "            r,\n",
    "            attack_model_name,\n",
    "            method_name\n",
    "        )\n",
    "        train_list.append(train_prob)\n",
    "        test_list.append(test_prob)\n",
    "\n",
    "    train_prob_combined = np.concatenate(train_list, axis=1)\n",
    "    test_prob_combined  = np.concatenate(test_list, axis=1)\n",
    "\n",
    "    train_prob_combined = torch.tensor(train_prob_combined, dtype=torch.float32)\n",
    "    test_prob_combined  = torch.tensor(test_prob_combined, dtype=torch.float32)\n",
    "\n",
    "    return train_prob_combined, test_prob_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c7e0d38-33a3-495f-97c9-b62efbe528c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20000, 10])\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "ratios = [0.6, 0.7, 0.8, 0.9, 'int8']\n",
    "\n",
    "train_prob_combined, test_prob_combined = build_concat_dataset(\n",
    "    save_folder_compress,\n",
    "    ratios,\n",
    "    attack_model_name,\n",
    "    method_name\n",
    ")\n",
    "print(train_prob_combined.shape)\n",
    "print(len(test_prob_combined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6868ac5-9d3d-4af7-8777-b28106610668",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data1, data2, labels):\n",
    "        self.data1 = data1\n",
    "        self.data2 = data2\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.data1)\n",
    "    def __getitem__(self, idx):\n",
    "        data1 = self.data1[idx]\n",
    "        data2 = self.data2[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        return data1, data2, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad263885-2025-45e2-b9a8-73d2cc091afb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2394f03b-addc-4fc3-98c8-70b9b50dd4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_labels))\n",
    "print(len(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "acd6dc83-83dd-4f8e-8805-ab9d11946c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_prob_combined, train_loss, train_labels)\n",
    "test_dataset = CustomDataset(test_prob_combined,test_loss,test_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1094860b-798d-4796-aea1-6be867dcd7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "compress_num = 5 # number of compress model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bdceaf2c-55ed-4682-8baf-3c1e13defbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttackModel(nn.Module):\n",
    "    def __init__(self, class_num):\n",
    "        super(AttackModel, self).__init__()\n",
    "\n",
    "        self.prob_component = nn.Sequential(\n",
    "            nn.Linear(2*compress_num, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(128, 64),\n",
    "        )\n",
    "\n",
    "        self.loss_component = nn.Sequential(\n",
    "            nn.Linear(1*compress_num, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(128, 64),\n",
    "        )\n",
    "\n",
    "        \n",
    "        self.encoder_component = nn.Sequential(\n",
    "           nn.Dropout(p=0.5),\n",
    "            nn.Linear(64*2 , 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(64, 2),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, prob, loss):\n",
    "        prob_component_result = self.prob_component(prob)\n",
    "        loss_component_result = self.loss_component(loss)\n",
    "        final_input = torch.cat((prob_component_result, loss_component_result), 1)\n",
    "        final_result = self.encoder_component(final_input)\n",
    "        return final_result, final_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1c148b9c-0819-4efa-a11a-b1b509ca718b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "def train_mia_attack_model(model, attack_train_loader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    for batch_idx, (input1,input2, member_status) in enumerate(attack_train_loader):\n",
    "        input1 = input1.to(device)\n",
    "        input2 = input2.to(device)\n",
    "\n",
    "        output,_ = model(input1,input2)        \n",
    "        member_status = member_status.to(device)\n",
    "        loss = loss_fn(output, member_status.long())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(member_status.view_as(pred)).sum().item()\n",
    "        \n",
    "    train_loss /= len(attack_train_loader.dataset)\n",
    "    accuracy = 100. * correct / len(attack_train_loader.dataset)\n",
    "    return train_loss, accuracy / 100\n",
    "\n",
    "def test_mia_attack_model(model, attack_test_loader, loss_fn, device):                 \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    all_ground_truth = []\n",
    "    all_pred_probs = []\n",
    "    final_inputs = []\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (input1, input2, member_status) in enumerate(attack_test_loader):\n",
    "            input1 = input1.to(device)\n",
    "            input2 = input2.to(device)\n",
    "            #input3 = input3.to(device)\n",
    "            \n",
    "            output,final_input = model(input1, input2) \n",
    "            final_inputs.append(final_input.detach().cpu())\n",
    "            member_status = member_status.to(device)\n",
    "\n",
    "            \n",
    "            test_loss += loss_fn(output, member_status.long()).item()\n",
    "            \n",
    "            probs = torch.softmax(output, dim=1)[:, 1]  \n",
    "            all_pred_probs.extend(probs.cpu().numpy())  \n",
    "            all_ground_truth.extend(member_status.cpu().numpy())  \n",
    "            \n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(member_status.view_as(pred)).sum().item()\n",
    "    \n",
    "    test_loss /= len(attack_test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(attack_test_loader.dataset)\n",
    "    \n",
    "    auc = roc_auc_score(all_ground_truth, all_pred_probs)\n",
    "    \n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(all_ground_truth, all_pred_probs)\n",
    "\n",
    "    fpr_target = 0.001\n",
    "    interp_func = interp1d(fpr, tpr)\n",
    "    tpr_at_low_fpr = interp_func(fpr_target)\n",
    "    final_inputs = torch.cat(final_inputs, dim=0)\n",
    "    return test_loss, accuracy / 100., auc, tpr_at_low_fpr*100, final_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ccf3c6-415b-4da5-8ae9-f7a03f3d025d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "56a4aeda-f7ba-4327-8514-ff0f03b7decb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------mia------------------\n",
      "epoch:0 \t tpr_at_0.001_fpr:3.1900 \t test_prec:0.6003 \t test_auc:0.7164 \t best_prec:0.6003 \t best_auc:0.7164\n",
      "epoch:1 \t tpr_at_0.001_fpr:4.8400 \t test_prec:0.6769 \t test_auc:0.7631 \t best_prec:0.6769 \t best_auc:0.7631\n",
      "epoch:2 \t tpr_at_0.001_fpr:5.0100 \t test_prec:0.6881 \t test_auc:0.7648 \t best_prec:0.6881 \t best_auc:0.7648\n",
      "epoch:3 \t tpr_at_0.001_fpr:5.2500 \t test_prec:0.6850 \t test_auc:0.7638 \t best_prec:0.6881 \t best_auc:0.7648\n",
      "epoch:4 \t tpr_at_0.001_fpr:4.8400 \t test_prec:0.6869 \t test_auc:0.7639 \t best_prec:0.6881 \t best_auc:0.7648\n",
      "epoch:5 \t tpr_at_0.001_fpr:4.7200 \t test_prec:0.6836 \t test_auc:0.7622 \t best_prec:0.6881 \t best_auc:0.7648\n",
      "epoch:6 \t tpr_at_0.001_fpr:4.6000 \t test_prec:0.6805 \t test_auc:0.7614 \t best_prec:0.6881 \t best_auc:0.7648\n",
      "epoch:7 \t tpr_at_0.001_fpr:4.4000 \t test_prec:0.6847 \t test_auc:0.7613 \t best_prec:0.6881 \t best_auc:0.7648\n",
      "epoch:8 \t tpr_at_0.001_fpr:4.1200 \t test_prec:0.6830 \t test_auc:0.7615 \t best_prec:0.6881 \t best_auc:0.7648\n",
      "epoch:9 \t tpr_at_0.001_fpr:4.2800 \t test_prec:0.6835 \t test_auc:0.7615 \t best_prec:0.6881 \t best_auc:0.7648\n",
      "epoch:10 \t tpr_at_0.001_fpr:4.2500 \t test_prec:0.6827 \t test_auc:0.7603 \t best_prec:0.6881 \t best_auc:0.7648\n",
      "epoch:11 \t tpr_at_0.001_fpr:4.3400 \t test_prec:0.6812 \t test_auc:0.7592 \t best_prec:0.6881 \t best_auc:0.7648\n",
      "epoch:12 \t tpr_at_0.001_fpr:4.4800 \t test_prec:0.6846 \t test_auc:0.7625 \t best_prec:0.6881 \t best_auc:0.7648\n",
      "epoch:13 \t tpr_at_0.001_fpr:4.4300 \t test_prec:0.6800 \t test_auc:0.7600 \t best_prec:0.6881 \t best_auc:0.7648\n",
      "epoch:14 \t tpr_at_0.001_fpr:4.4500 \t test_prec:0.6834 \t test_auc:0.7613 \t best_prec:0.6881 \t best_auc:0.7648\n",
      "epoch:15 \t tpr_at_0.001_fpr:4.4200 \t test_prec:0.6857 \t test_auc:0.7628 \t best_prec:0.6881 \t best_auc:0.7648\n",
      "epoch:16 \t tpr_at_0.001_fpr:4.4000 \t test_prec:0.6833 \t test_auc:0.7616 \t best_prec:0.6881 \t best_auc:0.7648\n",
      "epoch:17 \t tpr_at_0.001_fpr:4.2800 \t test_prec:0.6893 \t test_auc:0.7641 \t best_prec:0.6893 \t best_auc:0.7641\n",
      "epoch:18 \t tpr_at_0.001_fpr:4.3200 \t test_prec:0.6875 \t test_auc:0.7638 \t best_prec:0.6893 \t best_auc:0.7641\n",
      "epoch:19 \t tpr_at_0.001_fpr:4.3800 \t test_prec:0.6860 \t test_auc:0.7652 \t best_prec:0.6893 \t best_auc:0.7641\n",
      "epoch:20 \t tpr_at_0.001_fpr:4.4600 \t test_prec:0.6870 \t test_auc:0.7659 \t best_prec:0.6893 \t best_auc:0.7641\n",
      "epoch:21 \t tpr_at_0.001_fpr:4.4100 \t test_prec:0.6847 \t test_auc:0.7618 \t best_prec:0.6893 \t best_auc:0.7641\n",
      "epoch:22 \t tpr_at_0.001_fpr:4.3000 \t test_prec:0.6819 \t test_auc:0.7619 \t best_prec:0.6893 \t best_auc:0.7641\n",
      "epoch:23 \t tpr_at_0.001_fpr:4.3600 \t test_prec:0.6920 \t test_auc:0.7690 \t best_prec:0.6920 \t best_auc:0.7690\n",
      "epoch:24 \t tpr_at_0.001_fpr:4.2600 \t test_prec:0.6924 \t test_auc:0.7702 \t best_prec:0.6924 \t best_auc:0.7702\n",
      "epoch:25 \t tpr_at_0.001_fpr:4.0200 \t test_prec:0.6844 \t test_auc:0.7613 \t best_prec:0.6924 \t best_auc:0.7702\n",
      "epoch:26 \t tpr_at_0.001_fpr:4.0700 \t test_prec:0.6895 \t test_auc:0.7674 \t best_prec:0.6924 \t best_auc:0.7702\n",
      "epoch:27 \t tpr_at_0.001_fpr:4.1900 \t test_prec:0.6860 \t test_auc:0.7656 \t best_prec:0.6924 \t best_auc:0.7702\n",
      "epoch:28 \t tpr_at_0.001_fpr:3.9500 \t test_prec:0.6952 \t test_auc:0.7730 \t best_prec:0.6952 \t best_auc:0.7730\n",
      "epoch:29 \t tpr_at_0.001_fpr:4.3300 \t test_prec:0.6997 \t test_auc:0.7757 \t best_prec:0.6997 \t best_auc:0.7757\n",
      "epoch:30 \t tpr_at_0.001_fpr:4.1000 \t test_prec:0.6917 \t test_auc:0.7698 \t best_prec:0.6997 \t best_auc:0.7757\n",
      "epoch:31 \t tpr_at_0.001_fpr:4.0600 \t test_prec:0.6889 \t test_auc:0.7675 \t best_prec:0.6997 \t best_auc:0.7757\n",
      "epoch:32 \t tpr_at_0.001_fpr:4.1100 \t test_prec:0.6924 \t test_auc:0.7708 \t best_prec:0.6997 \t best_auc:0.7757\n",
      "epoch:33 \t tpr_at_0.001_fpr:4.1700 \t test_prec:0.6960 \t test_auc:0.7730 \t best_prec:0.6997 \t best_auc:0.7757\n",
      "epoch:34 \t tpr_at_0.001_fpr:4.0400 \t test_prec:0.6892 \t test_auc:0.7662 \t best_prec:0.6997 \t best_auc:0.7757\n",
      "epoch:35 \t tpr_at_0.001_fpr:4.1400 \t test_prec:0.6945 \t test_auc:0.7722 \t best_prec:0.6997 \t best_auc:0.7757\n",
      "epoch:36 \t tpr_at_0.001_fpr:4.0100 \t test_prec:0.6928 \t test_auc:0.7719 \t best_prec:0.6997 \t best_auc:0.7757\n",
      "epoch:37 \t tpr_at_0.001_fpr:3.9600 \t test_prec:0.6872 \t test_auc:0.7667 \t best_prec:0.6997 \t best_auc:0.7757\n",
      "epoch:38 \t tpr_at_0.001_fpr:4.3300 \t test_prec:0.6980 \t test_auc:0.7762 \t best_prec:0.6997 \t best_auc:0.7757\n",
      "epoch:39 \t tpr_at_0.001_fpr:4.0300 \t test_prec:0.6928 \t test_auc:0.7716 \t best_prec:0.6997 \t best_auc:0.7757\n",
      "epoch:40 \t tpr_at_0.001_fpr:4.0900 \t test_prec:0.6925 \t test_auc:0.7740 \t best_prec:0.6997 \t best_auc:0.7757\n",
      "epoch:41 \t tpr_at_0.001_fpr:4.1400 \t test_prec:0.6969 \t test_auc:0.7740 \t best_prec:0.6997 \t best_auc:0.7757\n",
      "epoch:42 \t tpr_at_0.001_fpr:4.0800 \t test_prec:0.6952 \t test_auc:0.7736 \t best_prec:0.6997 \t best_auc:0.7757\n",
      "epoch:43 \t tpr_at_0.001_fpr:4.0400 \t test_prec:0.6913 \t test_auc:0.7711 \t best_prec:0.6997 \t best_auc:0.7757\n",
      "epoch:44 \t tpr_at_0.001_fpr:4.0400 \t test_prec:0.6961 \t test_auc:0.7747 \t best_prec:0.6997 \t best_auc:0.7757\n",
      "epoch:45 \t tpr_at_0.001_fpr:4.3900 \t test_prec:0.7036 \t test_auc:0.7814 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:46 \t tpr_at_0.001_fpr:4.0700 \t test_prec:0.6953 \t test_auc:0.7742 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:47 \t tpr_at_0.001_fpr:4.0700 \t test_prec:0.6976 \t test_auc:0.7766 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:48 \t tpr_at_0.001_fpr:4.0600 \t test_prec:0.6941 \t test_auc:0.7720 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:49 \t tpr_at_0.001_fpr:4.2400 \t test_prec:0.7017 \t test_auc:0.7796 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:50 \t tpr_at_0.001_fpr:4.0800 \t test_prec:0.6985 \t test_auc:0.7767 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:51 \t tpr_at_0.001_fpr:3.9700 \t test_prec:0.6946 \t test_auc:0.7730 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:52 \t tpr_at_0.001_fpr:4.0700 \t test_prec:0.6974 \t test_auc:0.7750 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:53 \t tpr_at_0.001_fpr:4.1100 \t test_prec:0.6915 \t test_auc:0.7719 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:54 \t tpr_at_0.001_fpr:4.2400 \t test_prec:0.6980 \t test_auc:0.7778 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:55 \t tpr_at_0.001_fpr:4.4400 \t test_prec:0.7015 \t test_auc:0.7800 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:56 \t tpr_at_0.001_fpr:4.0900 \t test_prec:0.6941 \t test_auc:0.7728 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:57 \t tpr_at_0.001_fpr:4.1600 \t test_prec:0.6954 \t test_auc:0.7752 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:58 \t tpr_at_0.001_fpr:4.2100 \t test_prec:0.6956 \t test_auc:0.7752 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:59 \t tpr_at_0.001_fpr:4.1900 \t test_prec:0.6959 \t test_auc:0.7759 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:60 \t tpr_at_0.001_fpr:4.2600 \t test_prec:0.6952 \t test_auc:0.7766 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:61 \t tpr_at_0.001_fpr:4.2300 \t test_prec:0.6937 \t test_auc:0.7728 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:62 \t tpr_at_0.001_fpr:4.3900 \t test_prec:0.7023 \t test_auc:0.7809 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:63 \t tpr_at_0.001_fpr:4.2700 \t test_prec:0.6978 \t test_auc:0.7764 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:64 \t tpr_at_0.001_fpr:4.3100 \t test_prec:0.6978 \t test_auc:0.7766 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:65 \t tpr_at_0.001_fpr:4.1900 \t test_prec:0.6931 \t test_auc:0.7740 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:66 \t tpr_at_0.001_fpr:4.3700 \t test_prec:0.6972 \t test_auc:0.7777 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:67 \t tpr_at_0.001_fpr:4.3200 \t test_prec:0.7003 \t test_auc:0.7796 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:68 \t tpr_at_0.001_fpr:4.3600 \t test_prec:0.6998 \t test_auc:0.7779 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:69 \t tpr_at_0.001_fpr:4.3400 \t test_prec:0.6944 \t test_auc:0.7753 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:70 \t tpr_at_0.001_fpr:4.4800 \t test_prec:0.6990 \t test_auc:0.7778 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:71 \t tpr_at_0.001_fpr:4.4100 \t test_prec:0.6956 \t test_auc:0.7767 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:72 \t tpr_at_0.001_fpr:4.3700 \t test_prec:0.6984 \t test_auc:0.7765 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:73 \t tpr_at_0.001_fpr:4.3300 \t test_prec:0.6972 \t test_auc:0.7758 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:74 \t tpr_at_0.001_fpr:4.4500 \t test_prec:0.6978 \t test_auc:0.7765 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:75 \t tpr_at_0.001_fpr:4.4200 \t test_prec:0.6962 \t test_auc:0.7755 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:76 \t tpr_at_0.001_fpr:4.4100 \t test_prec:0.6937 \t test_auc:0.7739 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:77 \t tpr_at_0.001_fpr:4.4900 \t test_prec:0.6943 \t test_auc:0.7761 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:78 \t tpr_at_0.001_fpr:4.4600 \t test_prec:0.6963 \t test_auc:0.7764 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:79 \t tpr_at_0.001_fpr:4.4200 \t test_prec:0.6972 \t test_auc:0.7770 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:80 \t tpr_at_0.001_fpr:4.4400 \t test_prec:0.6944 \t test_auc:0.7759 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:81 \t tpr_at_0.001_fpr:4.4600 \t test_prec:0.6980 \t test_auc:0.7774 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:82 \t tpr_at_0.001_fpr:4.5000 \t test_prec:0.6987 \t test_auc:0.7794 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:83 \t tpr_at_0.001_fpr:4.3900 \t test_prec:0.6960 \t test_auc:0.7764 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:84 \t tpr_at_0.001_fpr:4.4100 \t test_prec:0.6961 \t test_auc:0.7760 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:85 \t tpr_at_0.001_fpr:4.4600 \t test_prec:0.6973 \t test_auc:0.7771 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:86 \t tpr_at_0.001_fpr:4.4600 \t test_prec:0.6978 \t test_auc:0.7774 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:87 \t tpr_at_0.001_fpr:4.4600 \t test_prec:0.6964 \t test_auc:0.7765 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:88 \t tpr_at_0.001_fpr:4.4900 \t test_prec:0.6960 \t test_auc:0.7770 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:89 \t tpr_at_0.001_fpr:4.5300 \t test_prec:0.6989 \t test_auc:0.7780 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:90 \t tpr_at_0.001_fpr:4.4800 \t test_prec:0.6974 \t test_auc:0.7772 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:91 \t tpr_at_0.001_fpr:4.4800 \t test_prec:0.6980 \t test_auc:0.7773 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:92 \t tpr_at_0.001_fpr:4.4800 \t test_prec:0.6976 \t test_auc:0.7770 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:93 \t tpr_at_0.001_fpr:4.5000 \t test_prec:0.6980 \t test_auc:0.7773 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:94 \t tpr_at_0.001_fpr:4.4700 \t test_prec:0.6981 \t test_auc:0.7774 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:95 \t tpr_at_0.001_fpr:4.4700 \t test_prec:0.6981 \t test_auc:0.7774 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:96 \t tpr_at_0.001_fpr:4.4700 \t test_prec:0.6981 \t test_auc:0.7773 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:97 \t tpr_at_0.001_fpr:4.4700 \t test_prec:0.6978 \t test_auc:0.7773 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:98 \t tpr_at_0.001_fpr:4.4700 \t test_prec:0.6978 \t test_auc:0.7773 \t best_prec:0.7036 \t best_auc:0.7814\n",
      "epoch:99 \t tpr_at_0.001_fpr:4.4700 \t test_prec:0.6978 \t test_auc:0.7773 \t best_prec:0.7036 \t best_auc:0.7814\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(f'-------------------mia------------------')\n",
    "attack_model = AttackModel(num_cls)\n",
    "epoch = 100\n",
    "attack_optimizer = torch.optim.SGD(attack_model.parameters(), 1e-2, momentum=0.9, weight_decay=5e-4)\n",
    "attack_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(attack_optimizer, T_max=epoch)\n",
    "attack_model = attack_model.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "best_prec = 0.0\n",
    "best_auc = 0.0\n",
    "for epoch in range(epoch):\n",
    "    train_loss, train_prec = train_mia_attack_model(attack_model, train_loader, attack_optimizer, loss_fn, device)\n",
    "    val_loss, val_prec, auc, tpr_at_low_fpr, final_inputs = test_mia_attack_model(attack_model, test_loader, loss_fn, device)\n",
    "    attack_scheduler.step()\n",
    "    is_best_prec = val_prec > best_prec\n",
    "    if is_best_prec:\n",
    "        best_prec = val_prec\n",
    "        best_auc = auc\n",
    "    #print(('epoch:{} \\t tpr_at_0.001_fpr:{:.4f} \\t test_prec:{:.4f} \\t test_auc:{:.4f} \\t best_prec:{:.4f} \\t best_auc:{:.4f}'.format(epoch, tpr_at_low_fpr, val_prec, auc, best_prec, best_auc))\n",
    "\n",
    "    print('epoch:{} \\t tpr_at_0.001_fpr:{:.4f} \\t test_prec:{:.4f} \\t test_auc:{:.4f} \\t best_prec:{:.4f} \\t best_auc:{:.4f}'.format(epoch, tpr_at_low_fpr, val_prec, auc, best_prec, best_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebc01a9-0df0-4aab-9b65-05a5165df346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8503b2d4-6532-4507-b841-2aed98f27727",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
